{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3211a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea17cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Load data using a relative path\n",
    "df = pd.read_csv(\"../ProcessDataIntegration/output/Interpolated_Geometry_With_Process_Params.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda3c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "# üìä 2. Segmentation by arc_id\n",
    "precision = 1.0\n",
    "segmented = []\n",
    "for lid in sorted(df['layer_id'].unique()):\n",
    "    layer_df = df[df['layer_id'] == lid].copy()\n",
    "    layer_df['arc_id'] = (layer_df['X'] / precision).round().astype(int)\n",
    "    layer_df['arc_id'] = layer_df['arc_id'] - layer_df['arc_id'].min() + 1  # ‚Üê starts from 1\n",
    "    segmented.append(layer_df)\n",
    "\n",
    "df_all = pd.concat(segmented, ignore_index=True)\n",
    "\n",
    "# üß† 3. Hover info\n",
    "df_all['info'] = (\n",
    "    \"Layer: \" + df_all['layer_id'].astype(str) +\n",
    "    \"<br>Arc ID: \" + df_all['arc_id'].astype(str) +\n",
    "    \"<br>I: \" + df_all['proc_I'].round(2).astype(str) +\n",
    "    \"<br>U: \" + df_all['proc_U'].round(2).astype(str) +\n",
    "    \"<br>WFS: \" + df_all['proc_WFS'].round(2).astype(str) +\n",
    "    \"<br>Speed: \" + df_all['proc_speed'].round(2).astype(str) +\n",
    "    \"<br>X=\" + df_all['X'].round(2).astype(str) +\n",
    "    \"<br>Y=\" + df_all['Y'].round(2).astype(str) +\n",
    "    \"<br>Z=\" + df_all['Z'].round(2).astype(str)\n",
    ")\n",
    "\n",
    "# ‚öôÔ∏è 4. Z-based anomaly detection with neighbors (trimmed)\n",
    "threshold_z_drop = 1.0\n",
    "layer_ids = sorted(df_all['layer_id'].unique())\n",
    "trimmed_anomaly_points = []\n",
    "\n",
    "for i in range(1, len(layer_ids) - 1):\n",
    "    lid_prev, lid_curr, lid_next = layer_ids[i - 1], layer_ids[i], layer_ids[i + 1]\n",
    "    df_prev = df_all[df_all['layer_id'] == lid_prev]\n",
    "    df_curr = df_all[df_all['layer_id'] == lid_curr]\n",
    "    df_next = df_all[df_all['layer_id'] == lid_next]\n",
    "\n",
    "    common_arc_ids = set(df_curr['arc_id']).intersection(df_prev['arc_id'], df_next['arc_id'])\n",
    "\n",
    "    for arc_id in common_arc_ids:\n",
    "        curr_arc = df_curr[df_curr['arc_id'] == arc_id].sort_values(by='X')\n",
    "        prev_arc = df_prev[df_prev['arc_id'] == arc_id].sort_values(by='X')\n",
    "        next_arc = df_next[df_next['arc_id'] == arc_id].sort_values(by='X')\n",
    "\n",
    "        def trim(df_arc):\n",
    "            n = len(df_arc)\n",
    "            if n < 10:\n",
    "                return df_arc\n",
    "            return df_arc.iloc[int(n * 0.05): int(n * 0.95)]\n",
    "\n",
    "        trimmed_curr = trim(curr_arc)\n",
    "        z_curr = trimmed_curr['Z'].mean()\n",
    "        z_prev = trim(prev_arc)['Z'].mean()\n",
    "        z_next = trim(next_arc)['Z'].mean()\n",
    "\n",
    "        z_neighbors_avg = (z_prev + z_next) / 2\n",
    "\n",
    "        if (z_neighbors_avg - z_curr) > threshold_z_drop:\n",
    "            trimmed_anomaly_points.append(trimmed_curr)\n",
    "\n",
    "# üì¶ 5. Combine anomaly points\n",
    "df_trimmed_anomalies = pd.concat(trimmed_anomaly_points, ignore_index=True)\n",
    "df_trimmed_anomalies['Anomalies'] = True\n",
    "\n",
    "# üî¥ 6. Mark anomalies in df_all\n",
    "df_all['Anomalies'] = False\n",
    "trimmed_keys = set(zip(\n",
    "    df_trimmed_anomalies['X'].round(5),\n",
    "    df_trimmed_anomalies['Y'].round(5),\n",
    "    df_trimmed_anomalies['Z'].round(5)\n",
    "))\n",
    "df_all['Anomalies'] = df_all.apply(\n",
    "    lambda row: (round(row['X'], 5), round(row['Y'], 5), round(row['Z'], 5)) in trimmed_keys,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# üß™ 7. Save to CSV (optional)\n",
    "\n",
    "# üìä 8. Visualization\n",
    "unique_layers = sorted(df_all['layer_id'].unique())\n",
    "layer_id_map = {old: new + 1 for new, old in enumerate(unique_layers)}\n",
    "df_all['layer_id_mapped'] = df_all['layer_id'].map(layer_id_map)\n",
    "df_trimmed_anomalies['layer_id_mapped'] = df_trimmed_anomalies['layer_id'].map(layer_id_map)\n",
    "layer_colors = ['black'] * len(unique_layers)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# ‚ö´ All points by layer\n",
    "for lid in sorted(df_all['layer_id_mapped'].unique()):\n",
    "    layer_df = df_all[df_all['layer_id_mapped'] == lid]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=layer_df['X'], y=layer_df['Y'], z=layer_df['Z'],\n",
    "        mode='markers',\n",
    "        name=f\"Layer {lid}\",\n",
    "        text=layer_df['info'],\n",
    "        marker=dict(size=2, color=layer_colors[lid - 1], opacity=0.8),\n",
    "        hoverinfo='text',\n",
    "        visible=True\n",
    "    ))\n",
    "\n",
    "# üî¥ Trimmed anomalies\n",
    "for lid in sorted(df_trimmed_anomalies['layer_id_mapped'].unique()):\n",
    "    trimmed_layer_df = df_trimmed_anomalies[df_trimmed_anomalies['layer_id_mapped'] == lid]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=trimmed_layer_df['X'], y=trimmed_layer_df['Y'], z=trimmed_layer_df['Z'],\n",
    "        mode='markers',\n",
    "        name=f\"Anomalies (Layer {lid})\",\n",
    "        text=trimmed_layer_df['info'],\n",
    "        marker=dict(size=3, color='red', opacity=1.0),\n",
    "        hoverinfo='text',\n",
    "        visible=True\n",
    "    ))\n",
    "\n",
    "# üìê Plot layout configuration\n",
    "x_range = [df_all['X'].min(), df_all['X'].max()]\n",
    "y_range = [df_all['Y'].min(), df_all['Y'].max()]\n",
    "z_range = [df_all['Z'].min(), df_all['Z'].max()]\n",
    "\n",
    "axis_length = max(\n",
    "    x_range[1] - x_range[0],\n",
    "    y_range[1] - y_range[0],\n",
    "    z_range[1] - z_range[0]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Anomalies\",\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='X', range=[x_range[0], x_range[0] + axis_length]),\n",
    "        yaxis=dict(title='Y', range=[y_range[0], y_range[0] + axis_length]),\n",
    "        zaxis=dict(title='Z', range=[z_range[0], z_range[0] + axis_length]),\n",
    "        aspectmode='manual',\n",
    "        aspectratio=dict(x=1, y=1, z=0.4),\n",
    "        camera=dict(eye=dict(x=1.25, y=1.25, z=1.25))\n",
    "    ),\n",
    "    height=750,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# fig.show()\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c505c323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Plot saved: ./output\\3D_DetectAnomalies_layers.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# üìÅ Path to the output directory next to this notebook\n",
    "output_dir = \"./output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# üìÑ Path to the HTML file\n",
    "output_path = os.path.join(output_dir, \"3D_DetectAnomalies_layers.html\")\n",
    "\n",
    "# üíæ Save the figure\n",
    "fig.write_html(output_path)\n",
    "print(f\"‚úÖ Plot saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffabe90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved to: C:\\Users\\kopil\\OneDrive\\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\\Projects\\Additive_lab_robots\\RaTSiF\\data\\framework\\src\\AnomalyDetection\\output\\DetectAnomalies.csv\n"
     ]
    }
   ],
   "source": [
    "# === 6. Save the result to CSV ===\n",
    "from pathlib import Path\n",
    "\n",
    "# Create the output folder (if it doesn't exist yet)\n",
    "output_dir = Path(\"output\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Path to the file\n",
    "output_path = output_dir / \"DetectAnomalies.csv\"\n",
    "\n",
    "# Save the DataFrame\n",
    "df_all.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Saved to: {output_path.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
